import streamlit as st
import pandas as pd
import re
import json
import io
from typing import Dict, List, Tuple, Optional
from difflib import SequenceMatcher
import unicodedata
import numpy as np

# Imports pour NLP avanc√©
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.feature_extraction.text import TfidfVectorizer
    NLP_AVAILABLE = True
except ImportError:
    NLP_AVAILABLE = False

class AdvancedKeywordCategorizer:
    """
    Cat√©goriseur avanc√© avec IA qui pr√©serve la structure du fichier d'entr√©e
    """
    
    def __init__(self):
        self.categories = {}
        self.use_advanced_nlp = False
        self.model = None
        self.tfidf_vectorizer = None
        
        # Tentative d'initialisation du mod√®le NLP
        if NLP_AVAILABLE:
            try:
                st.info("Chargement du mod√®le de langue avanc√©...")
                # Mod√®le multilingue optimis√©
                self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                self.tfidf_vectorizer = TfidfVectorizer(
                    ngram_range=(1, 2),
                    max_features=1000,
                    stop_words=None,
                    lowercase=True
                )
                self.use_advanced_nlp = True
                st.success("‚úÖ Mod√®le NLP avanc√© charg√© avec succ√®s!")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Impossible de charger le mod√®le NLP avanc√©: {str(e)}")
                st.info("üìù Utilisation de l'algorithme de base")
                self.use_advanced_nlp = False
        else:
            st.warning("‚ö†Ô∏è D√©pendances NLP manquantes. Installation recommand√©e :")
            st.code("pip install sentence-transformers scikit-learn torch")
            st.info("üìù Utilisation de l'algorithme de base")
    
    def normalize_text(self, text: str) -> str:
        """
        Normalise le texte pour une meilleure comparaison
        """
        # Convertir en minuscules
        text = text.lower().strip()
        # Supprimer les accents
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        # Supprimer la ponctuation et caract√®res sp√©ciaux
        text = re.sub(r'[^\w\s]', ' ', text)
        # Supprimer les espaces multiples
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    def calculate_similarity_basic(self, text1: str, text2: str) -> float:
        """
        Calcule la similarit√© entre deux textes avec l'algorithme de base
        """
        text1_norm = self.normalize_text(text1)
        text2_norm = self.normalize_text(text2)
        
        # Similarit√© de s√©quence globale
        seq_similarity = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        # Similarit√© par mots
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if len(words1) == 0 and len(words2) == 0:
            word_similarity = 1.0
        elif len(words1) == 0 or len(words2) == 0:
            word_similarity = 0.0
        else:
            intersection = len(words1.intersection(words2))
            union = len(words1.union(words2))
            word_similarity = intersection / union if union > 0 else 0.0
        
        # Similarit√© de contenance (un mot contient l'autre)
        containment_similarity = 0.0
        if text1_norm in text2_norm or text2_norm in text1_norm:
            containment_similarity = 0.8
        
        # Score final pond√©r√©
        final_score = (seq_similarity * 0.4 + word_similarity * 0.4 + containment_similarity * 0.2)
        
        return final_score
    
    def calculate_similarity_advanced(self, keyword: str, category_terms: List[str]) -> Tuple[str, float]:
        """
        Calcule la similarit√© avec des embeddings s√©mantiques avanc√©s
        """
        try:
            # Cr√©er les embeddings
            keyword_embedding = self.model.encode([keyword])
            terms_embeddings = self.model.encode(category_terms)
            
            # Calculer la similarit√© cosinus
            similarities = cosine_similarity(keyword_embedding, terms_embeddings)[0]
            
            # Trouver le meilleur match
            best_idx = np.argmax(similarities)
            best_term = category_terms[best_idx]
            best_score = similarities[best_idx]
            
            # Bonus pour correspondance exacte ou partielle
            keyword_norm = self.normalize_text(keyword)
            for i, term in enumerate(category_terms):
                term_norm = self.normalize_text(term)
                
                # Correspondance exacte
                if keyword_norm == term_norm:
                    return term, 1.0
                
                # Correspondance partielle forte
                if keyword_norm in term_norm or term_norm in keyword_norm:
                    if similarities[i] + 0.3 > best_score:
                        best_score = min(1.0, similarities[i] + 0.3)
                        best_term = term
                        best_idx = i
            
            return best_term, float(best_score)
            
        except Exception as e:
            st.warning(f"Erreur dans l'analyse avanc√©e: {str(e)}")
            # Fallback vers l'algorithme de base
            best_score = 0.0
            best_term = category_terms[0]
            
            for term in category_terms:
                score = self.calculate_similarity_basic(keyword, term)
                if score > best_score:
                    best_score = score
                    best_term = term
            
            return best_term, best_score
    
    def calculate_tfidf_similarity(self, keyword: str, all_terms: List[str]) -> Dict[str, float]:
        """
        Calcule la similarit√© TF-IDF pour une analyse compl√©mentaire
        """
        try:
            # Pr√©parer le corpus
            corpus = [keyword] + all_terms
            
            # Vectorisation TF-IDF
            tfidf_matrix = self.tfidf_vectorizer.fit_transform(corpus)
            
            # Similarit√© cosinus
            keyword_vector = tfidf_matrix[0:1]
            terms_vectors = tfidf_matrix[1:]
            
            similarities = cosine_similarity(keyword_vector, terms_vectors)[0]
            
            # Cr√©er le dictionnaire de scores
            scores = {}
            for i, term in enumerate(all_terms):
                scores[term] = float(similarities[i])
                
            return scores
            
        except Exception as e:
            # Retour aux scores de base
            return {term: self.calculate_similarity_basic(keyword, term) for term in all_terms}
    
    def set_categories(self, categories_dict: Dict[str, List[str]]):
        """
        D√©finit les cat√©gories avec leurs termes de r√©f√©rence
        """
        self.categories = categories_dict
    
    def categorize_keyword(self, keyword: str) -> Tuple[str, str, float]:
        """
        Trouve OBLIGATOIREMENT la meilleure cat√©gorie pour un mot-cl√© avec IA avanc√©e
        """
        if not self.categories:
            return ("Aucune cat√©gorie", "Non d√©fini", 0.0)
        
        best_category = None
        best_term = None
        best_score = -1.0
        
        if self.use_advanced_nlp:
            # Approche IA avanc√©e
            try:
                # Pr√©parer tous les termes pour l'analyse globale
                all_terms = []
                term_to_category = {}
                
                for category_name, terms_list in self.categories.items():
                    for term in terms_list:
                        all_terms.append(term)
                        term_to_category[term] = category_name
                
                # Analyse s√©mantique par cat√©gorie
                category_scores = {}
                
                for category_name, terms_list in self.categories.items():
                    matched_term, score = self.calculate_similarity_advanced(keyword, terms_list)
                    category_scores[category_name] = (matched_term, score)
                
                # Analyse TF-IDF compl√©mentaire
                tfidf_scores = self.calculate_tfidf_similarity(keyword, all_terms)
                
                # Combinaison des scores
                for category_name, (matched_term, semantic_score) in category_scores.items():
                    # Score TF-IDF pour ce terme
                    tfidf_score = tfidf_scores.get(matched_term, 0.0)
                    
                    # Score final combin√© (70% s√©mantique, 30% TF-IDF)
                    combined_score = (semantic_score * 0.7) + (tfidf_score * 0.3)
                    
                    if combined_score > best_score:
                        best_score = combined_score
                        best_category = category_name
                        best_term = matched_term
                
            except Exception as e:
                st.warning(f"Erreur dans l'analyse IA: {str(e)}")
                # Fallback vers l'algorithme de base
                self.use_advanced_nlp = False
        
        if not self.use_advanced_nlp:
            # Approche de base en cas de probl√®me
            for category_name, terms_list in self.categories.items():
                for term in terms_list:
                    similarity = self.calculate_similarity_basic(keyword, term)
                    
                    if similarity > best_score:
                        best_score = similarity
                        best_category = category_name
                        best_term = term
        
        # Si aucune similarit√© trouv√©e, attribuer √† la premi√®re cat√©gorie
        if best_category is None:
            first_category = list(self.categories.keys())[0]
            first_term = self.categories[first_category][0] if self.categories[first_category] else "Non d√©fini"
            return (first_category, first_term, 0.0)
        
        return (best_category, best_term, best_score)
    
    def process_dataframe_preserve_structure(self, df: pd.DataFrame, keyword_column: str, 
                                           output_columns_mapping: Dict[str, str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Traite le DataFrame en pr√©servant EXACTEMENT la structure originale
        Ne modifie QUE les colonnes sp√©cifi√©es dans output_columns_mapping
        """
        # Cr√©er une copie exacte du DataFrame original
        result_df = df.copy()
        
        # V√©rifier que la colonne des mots-cl√©s existe
        if keyword_column not in df.columns:
            raise ValueError(f"Colonne '{keyword_column}' non trouv√©e dans le fichier")
        
        # V√©rifier que toutes les colonnes de sortie existent
        for output_col in output_columns_mapping.values():
            if output_col not in df.columns:
                raise ValueError(f"Colonne de sortie '{output_col}' non trouv√©e dans le fichier")
        
        # Cr√©er un DataFrame de statistiques s√©par√©
        stats_data = []
        
        # Traitement ligne par ligne
        for idx, row in df.iterrows():
            keyword = str(row[keyword_column])
            
            # Traiter m√™me les valeurs vides
            if pd.isna(keyword) or keyword.strip() == '' or keyword.lower() == 'nan':
                keyword = f"Vide_ligne_{idx+1}"
            
            # Cat√©gorisation
            category, matched_term, confidence = self.categorize_keyword(keyword)
            
            # Mettre √† jour UNIQUEMENT les colonnes sp√©cifi√©es
            for category_name, output_column in output_columns_mapping.items():
                if category_name == category:
                    result_df.at[idx, output_column] = matched_term
                else:
                    # Laisser vide ou mettre une valeur par d√©faut si ce n'est pas la bonne cat√©gorie
                    if pd.isna(result_df.at[idx, output_column]) or str(result_df.at[idx, output_column]).strip() == '':
                        result_df.at[idx, output_column] = ''
            
            # Collecter les statistiques
            stats_data.append({
                'Ligne': idx + 1,
                'Mot_cle_original': keyword,
                'Categorie_attribuee': category,
                'Terme_reference': matched_term,
                'Score_similarite': round(confidence, 3)
            })
        
        # Cr√©er le DataFrame de statistiques
        stats_df = pd.DataFrame(stats_data)
        
        return result_df, stats_df


def main():
    st.set_page_config(
        page_title="Script de cat√©gorisation de mots-cl√©s",
        page_icon="https://jc-espinosa.com/wp-content/uploads/2024/06/JC-Espinosa-Favicon-blue-150x150.png",
        layout="wide"
    )
    
    st.title("Script de cat√©gorisation de mots-cl√©s")
    st.markdown("**Pr√©serve exactement** la mise en forme de votre fichier d'entr√©e, ne modifie que les colonnes sp√©cifi√©es")
    
    # Encart d'informations et √©tapes d'utilisation
    with st.expander("Informations et √©tapes d'utilisation"):
        st.markdown("""
        ### Description de l'outil
        
        Cet outil utilise l'Intelligence Artificielle pour cat√©goriser automatiquement des mots-cl√©s en pr√©servant exactement la structure de votre fichier d'entr√©e. 
        Il combine plusieurs techniques NLP pour une cat√©gorisation pr√©cise et contextuelle.
        
        ### Technologies utilis√©es
        
        - **Embeddings s√©mantiques** : Mod√®le Sentence-BERT multilingue pour comprendre le sens,
        - **Similarit√© cosinus** : Mesure de proximit√© s√©mantique dans l'espace vectoriel,
        - **TF-IDF** : Analyse de fr√©quence des termes pour affiner les r√©sultats,
        - **Algorithme hybride** : Combinaison de 3 approches pour maximiser la pr√©cision.
        
        ### Fonctionnement
        
        - **Attribution forc√©e** : Chaque mot-cl√© est obligatoirement attribu√© √† une cat√©gorie,
        - **Pr√©servation de structure** : Votre fichier garde exactement sa mise en forme originale,
        - **IA contextuelle** : Comprend le sens et le contexte, pas seulement les mots-cl√©s,
        - **Multilingue** : Fonctionne en fran√ßais, anglais et autres langues europ√©ennes,
        - **Colonnes cibl√©es** : Seules les colonnes que vous sp√©cifiez sont modifi√©es.
        
        ### √âtapes d'utilisation
        
        1. **Configurez vos cat√©gories** : Cr√©ez vos cat√©gories et ajoutez les termes de r√©f√©rence pour chacune,
        2. **Importez votre fichier** : Chargez votre fichier Excel ou CSV avec la structure finale souhait√©e,
        3. **Configurez les colonnes** : S√©lectionnez la colonne des mots-cl√©s et assignez les colonnes de sortie pour chaque cat√©gorie,
        4. **Lancez le traitement IA** : L'outil analyse s√©mantiquement tous vos mots-cl√©s et les place dans les bonnes colonnes,
        5. **Exportez les r√©sultats** : T√©l√©chargez votre fichier final avec les statistiques de confiance.
        
        ### Format de fichier attendu
        
        Votre fichier d'entr√©e doit contenir :
        - Une colonne avec vos mots-cl√©s √† cat√©goriser,
        - Des colonnes vides ou existantes o√π placer les r√©sultats de chaque cat√©gorie,
        - Toute autre donn√©e que vous souhaitez conserver (elle sera pr√©serv√©e).
        
        ### Scores de confiance
        
        - **0.8-1.0** : Correspondance excellente (IA tr√®s confiante),
        - **0.6-0.8** : Correspondance bonne (contexte s√©mantique fort),
        - **0.4-0.6** : Correspondance acceptable (similarit√© d√©tect√©e),
        - **0.0-0.4** : Correspondance faible (attribution par d√©faut).
        """)
    
    # CSS pour les boutons en couleur fcf192
    st.markdown("""
    <style>
    .stButton > button[kind="primary"] {
        background-color: #fcf192 !important;
        color: #000000 !important;
        border: 1px solid #e6e600 !important;
    }
    .stButton > button[kind="primary"]:hover {
        background-color: #f0e85c !important;
        color: #000000 !important;
        border: 1px solid #cccc00 !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Initialisation
    if 'categorizer' not in st.session_state:
        st.session_state.categorizer = AdvancedKeywordCategorizer()
        st.session_state.categories_config = {}
        st.session_state.df_loaded = None
        st.session_state.columns_mapping = {}
    
    # √âtape 1: Configuration des cat√©gories
    st.header("√âtape 1 : Configuration des cat√©gories")
    
    col_config1, col_config2 = st.columns([1, 1])
    
    with col_config1:
        st.subheader("Ajouter une cat√©gorie")
        
        new_category_name = st.text_input(
            "Nom de la cat√©gorie :",
            placeholder="Ex: Produits, Services, Marques, Th√©matiques..."
        )
        
        new_category_terms = st.text_area(
            "Termes de r√©f√©rence pour cette cat√©gorie (un par ligne) :",
            placeholder="smartphone\ntablette\nordinateur\n...",
            height=120
        )
        
        if st.button("Ajouter cette cat√©gorie", type="primary"):
            if new_category_name and new_category_terms:
                # V√©rifier si la cat√©gorie existe d√©j√†
                if new_category_name in st.session_state.categories_config:
                    st.warning(f"La cat√©gorie '{new_category_name}' existe d√©j√†. Utilisez un autre nom.")
                else:
                    terms_list = [term.strip() for term in new_category_terms.split('\n') if term.strip()]
                    if len(terms_list) > 0:
                        st.session_state.categories_config[new_category_name] = terms_list
                        st.session_state.categorizer.set_categories(st.session_state.categories_config)
                        st.success(f"Cat√©gorie '{new_category_name}' ajout√©e avec {len(terms_list)} termes !")
                        # Forcer le rafra√Æchissement
                        st.rerun()
                    else:
                        st.error("Veuillez ajouter au moins un terme de r√©f√©rence")
            else:
                st.error("Veuillez remplir le nom et les termes de r√©f√©rence")
        
        # Bouton pour vider les champs
        if st.button("Vider les champs"):
            st.rerun()
    
    with col_config2:
        st.subheader("Cat√©gories configur√©es")
        
        if st.session_state.categories_config:
            for cat_name, terms in st.session_state.categories_config.items():
                with st.expander(f"{cat_name} ({len(terms)} termes)"):
                    st.write("**Termes de r√©f√©rence :**")
                    for i, term in enumerate(terms[:8], 1):
                        st.write(f"{i}. {term}")
                    if len(terms) > 8:
                        st.write(f"... et {len(terms) - 8} autres termes")
                    
                    if st.button(f"Supprimer {cat_name}", key=f"del_{cat_name}"):
                        del st.session_state.categories_config[cat_name]
                        st.session_state.categorizer.set_categories(st.session_state.categories_config)
                        st.rerun()
        else:
            st.info("Aucune cat√©gorie configur√©e. Ajoutez au moins une cat√©gorie pour commencer.")
    
    st.divider()
    
    # √âtape 2: Import du fichier
    st.header("√âtape 2 : Import du fichier structure")
    
    uploaded_file = st.file_uploader(
        "Choisissez votre fichier Excel ou CSV avec la structure finale souhait√©e",
        type=['xlsx', 'xls', 'csv'],
        help="Ce fichier doit contenir : colonne des mots-cl√©s + colonnes vides pour chaque cat√©gorie"
    )
    
    if uploaded_file is not None:
        try:
            # Lecture du fichier
            if uploaded_file.name.endswith('.csv'):
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except:
                    try:
                        df = pd.read_csv(uploaded_file, encoding='latin-1')
                    except:
                        df = pd.read_csv(uploaded_file, encoding='cp1252')
            else:
                df = pd.read_excel(uploaded_file)
            
            st.session_state.df_loaded = df
            st.success(f"Fichier charg√© : **{len(df):,} lignes** et **{len(df.columns)} colonnes**")
            
        except Exception as e:
            st.error(f"Erreur lors de la lecture du fichier : {str(e)}")
            return
    
    # √âTAPE 3: Configuration des colonnes
    if st.session_state.df_loaded is not None and st.session_state.categories_config:
        st.header("√âtape 3 : Configuration des colonnes")
        
        df = st.session_state.df_loaded
        
        col_mapping1, col_mapping2 = st.columns([1, 1])
        
        with col_mapping1:
            st.subheader("Colonne des mots-cl√©s")
            
            keyword_column = st.selectbox(
                "S√©lectionnez la colonne contenant les mots-cl√©s √† cat√©goriser :",
                options=df.columns.tolist(),
                help="Cette colonne contient les termes que vous voulez cat√©goriser"
            )
            
            # Aper√ßu de la colonne s√©lectionn√©e
            if keyword_column:
                st.write("**Aper√ßu des mots-cl√©s :**")
                sample_keywords = df[keyword_column].dropna().head(10).tolist()
                for i, kw in enumerate(sample_keywords, 1):
                    st.write(f"{i}. {kw}")
                if len(df[keyword_column].dropna()) > 10:
                    st.write(f"... et {len(df[keyword_column].dropna()) - 10} autres")
        
        with col_mapping2:
            st.subheader("Attribution des colonnes de sortie")
            
            st.write("Pour chaque cat√©gorie, choisissez dans quelle colonne mettre le r√©sultat :")
            
            columns_mapping = {}
            
            for category_name in st.session_state.categories_config.keys():
                output_column = st.selectbox(
                    f"Colonne pour '{category_name}' :",
                    options=df.columns.tolist(),
                    key=f"mapping_{category_name}",
                    help=f"Les termes de la cat√©gorie '{category_name}' seront plac√©s dans cette colonne"
                )
                columns_mapping[category_name] = output_column
            
            st.session_state.columns_mapping = columns_mapping
            
            # Validation
            if len(set(columns_mapping.values())) != len(columns_mapping.values()):
                st.warning("Attention : Vous avez assign√© plusieurs cat√©gories √† la m√™me colonne !")
        
        # Aper√ßu de la structure
        st.subheader("Aper√ßu de la structure du fichier")
        st.dataframe(df.head(), use_container_width=True)
        
        # R√©sum√© de la configuration
        st.subheader("R√©sum√© de la configuration")
        
        col_summary1, col_summary2 = st.columns(2)
        
        with col_summary1:
            st.write("**Configuration :**")
            st.write(f"‚Ä¢ Colonne mots-cl√©s : `{keyword_column}`")
            st.write(f"‚Ä¢ Nombre de lignes : `{len(df):,}`")
            st.write(f"‚Ä¢ Cat√©gories configur√©es : `{len(st.session_state.categories_config)}`")
        
        with col_summary2:
            st.write("**Attribution des colonnes :**")
            for cat, col in columns_mapping.items():
                st.write(f"‚Ä¢ {cat} ‚Üí `{col}`")
        
        st.divider()
        
        # √âtape 4: Traitement
        st.header("√âtape 4 : Traitement")
        
        if st.button("Lancer la cat√©gorisation", type="primary", use_container_width=True):
            if not columns_mapping:
                st.error("Veuillez configurer l'attribution des colonnes")
                return
            
            with st.spinner("Traitement en cours... Pr√©servation de la structure originale..."):
                try:
                    # Traitement avec pr√©servation de structure
                    result_df, stats_df = st.session_state.categorizer.process_dataframe_preserve_structure(
                        df, keyword_column, columns_mapping
                    )
                    
                    # Sauvegarde dans la session
                    st.session_state.result_df = result_df
                    st.session_state.stats_df = stats_df
                    
                    st.success("Traitement termin√© ! Structure originale pr√©serv√©e.")
                    
                    # Statistiques rapides
                    total_processed = len(stats_df)
                    categories_stats = stats_df['Categorie_attribuee'].value_counts()
                    avg_confidence = stats_df['Score_similarite'].mean()
                    
                    col_stats = st.columns(3)
                    with col_stats[0]:
                        st.metric("Mots-cl√©s trait√©s", f"{total_processed:,}")
                    with col_stats[1]:
                        st.metric("Score moyen", f"{avg_confidence:.3f}")
                    with col_stats[2]:
                        high_conf = len(stats_df[stats_df['Score_similarite'] >= 0.5])
                        st.metric("Haute confiance", f"{high_conf:,}")
                    
                except Exception as e:
                    st.error(f"Erreur lors du traitement : {str(e)}")
        
        # √âtape 5: R√©sultats et export
        if 'result_df' in st.session_state:
            st.header("√âtape 5 : R√©sultats et Export")
            
            result_df = st.session_state.result_df
            stats_df = st.session_state.stats_df
            
            # Onglets pour organiser l'affichage
            tab1, tab2, tab3 = st.tabs(["Fichier Final", "Statistiques", "Export"])
            
            with tab1:
                st.subheader("Aper√ßu du fichier final (structure pr√©serv√©e)")
                st.write("**Structure exactement identique √† l'entr√©e**, seules les colonnes assign√©es ont √©t√© modifi√©es :")
                
                # Afficher avec mise en √©vidence des colonnes modifi√©es
                display_df = result_df.copy()
                
                # Mettre en √©vidence les colonnes modifi√©es
                modified_columns = list(st.session_state.columns_mapping.values())
                st.write(f"**Colonnes modifi√©es :** {', '.join(modified_columns)}")
                
                # S√©lecteur pour le nombre de lignes √† afficher
                show_rows = st.selectbox("Lignes √† afficher :", [10, 50, 100, 500], index=1)
                st.dataframe(display_df.head(show_rows), use_container_width=True)
                
                st.write(f"**Total :** {len(result_df):,} lignes √ó {len(result_df.columns)} colonnes")
            
            with tab2:
                st.subheader("Statistiques d√©taill√©es")
                
                # R√©partition par cat√©gorie
                categories_stats = stats_df['Categorie_attribuee'].value_counts()
                st.bar_chart(categories_stats)
                
                # Distribution des scores
                st.subheader("Distribution des scores de similarit√©")
                
                # Cr√©er les bins pour l'histogramme sans matplotlib
                bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
                hist_data = pd.cut(stats_df['Score_similarite'], bins=bins, include_lowest=True).value_counts().sort_index()
                
                # Renommer les index pour plus de clart√©
                hist_data.index = [f"{interval.left:.1f}-{interval.right:.1f}" for interval in hist_data.index]
                
                st.bar_chart(hist_data)
                
                # D√©tails par cat√©gorie
                st.subheader("D√©tails par cat√©gorie")
                for category in categories_stats.index:
                    with st.expander(f"{category} ({categories_stats[category]} √©l√©ments)"):
                        cat_data = stats_df[stats_df['Categorie_attribuee'] == category]
                        avg_score = cat_data['Score_similarite'].mean()
                        st.write(f"**Score moyen :** {avg_score:.3f}")
                        
                        # Exemples avec scores les plus √©lev√©s
                        top_matches = cat_data.nlargest(5, 'Score_similarite')
                        st.write("**Meilleurs matches :**")
                        for _, row in top_matches.iterrows():
                            st.write(f"‚Ä¢ `{row['Mot_cle_original']}` ‚Üí `{row['Terme_reference']}` (score: {row['Score_similarite']:.3f})")
            
            with tab3:
                st.subheader("Export des r√©sultats")
                
                col_export1, col_export2 = st.columns(2)
                
                with col_export1:
                    st.write("**Fichier principal (structure pr√©serv√©e)**")
                    
                    # Export Excel du fichier final
                    output_main = io.BytesIO()
                    result_df.to_excel(output_main, index=False, engine='openpyxl')
                    excel_main_data = output_main.getvalue()
                    
                    st.download_button(
                        label="T√©l√©charger fichier final (.xlsx)",
                        data=excel_main_data,
                        file_name=f"fichier_categorise_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
                    
                    # Export CSV
                    csv_main_data = result_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="T√©l√©charger fichier final (.csv)",
                        data=csv_main_data,
                        file_name=f"fichier_categorise_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                
                with col_export2:
                    st.write("**Rapport d'analyse**")
                    
                    # Export Excel complet avec statistiques
                    output_complete = io.BytesIO()
                    with pd.ExcelWriter(output_complete, engine='openpyxl') as writer:
                        # Fichier final
                        result_df.to_excel(writer, sheet_name='Fichier_final', index=False)
                        
                        # Statistiques d√©taill√©es
                        stats_df.to_excel(writer, sheet_name='Statistiques_detail', index=False)
                        
                        # Synth√®se
                        synthesis_data = []
                        for category in categories_stats.index:
                            cat_data = stats_df[stats_df['Categorie_attribuee'] == category]
                            synthesis_data.append({
                                'Categorie': category,
                                'Nombre_elements': len(cat_data),
                                'Score_moyen': cat_data['Score_similarite'].mean(),
                                'Pourcentage': (len(cat_data) / len(stats_df)) * 100,
                                'Colonne_assignee': st.session_state.columns_mapping.get(category, 'Non assign√©')
                            })
                        
                        synthesis_df = pd.DataFrame(synthesis_data)
                        synthesis_df.to_excel(writer, sheet_name='Synthese', index=False)
                        
                        # Configuration
                        config_data = []
                        for cat_name, terms in st.session_state.categories_config.items():
                            for term in terms:
                                config_data.append({
                                    'Categorie': cat_name,
                                    'Terme_reference': term,
                                    'Colonne_sortie': st.session_state.columns_mapping.get(cat_name, 'Non assign√©')
                                })
                        
                        config_df = pd.DataFrame(config_data)
                        config_df.to_excel(writer, sheet_name='Configuration', index=False)
                    
                    excel_complete_data = output_complete.getvalue()
                    
                    st.download_button(
                        label="T√©l√©charger rapport complet (.xlsx)",
                        data=excel_complete_data,
                        file_name=f"rapport_complet_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
                
                # Informations sur l'export
                st.info("""
                **Contenu des exports :**
                ‚Ä¢ **Fichier final** : Structure exactement identique √† votre fichier d'entr√©e avec les colonnes cat√©goris√©es
                ‚Ä¢ **Rapport complet** : Fichier final + statistiques + configuration pour tra√ßabilit√©
                """)


if __name__ == "__main__":
    main()
